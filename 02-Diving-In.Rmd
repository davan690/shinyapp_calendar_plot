---
title: Methods
output: html_document
---

# Methods {#methods} 

Generally the concept is to create a baseline dataset of information and then extend this using `dataspice` to create a tidy format of data that can then be modelled and visualised using the `tidyverse` suite of tools.

## Data setup {.tabset}

```{r}
library(knitr)
knitr::include_graphics(path = "./img/TidyPipes-calenderJUL2020v2.png")
```

There are multiple difference sources of information for this calendar. To be able to keep this upto date and current I need to write scripts for each data-source to my database of events (here). These are the following importing scripts:

- Timeline figure
  - Past
  - Future

### Data/information

The purpose of this vignette is to show how, with reference to a real-world application: creating a timetable for a new module. It assumes youâ€™ve installed the package following instructions in the README and have attached it as follows:

Overall this is time series data. A good general tutorial for this sort of data is here on [youtube]("https://www.youtube.com/watch?v=uenWg7ZSu4Y"). There are several ways to visualise this data, below are two selected bits of code that do this. Overall there are two generalised datasets that may be helpful to other individuals for each project or combination of projects (for the APR for example). The data for this collection of tasks associated with timelines and targets. The baseline dataset is found in the `.xlsx` file named "baseline-dataset-calender.xlsx". This is the base file I have been adding information to when I change the overall structure of the calendar projects.

### Manual data (`.csv` files)

To begin with I have collated and restructured the avaliable data from downloaded `.ics` data as a csv and the UCSRC council calendar.

This sorted data was orginally saved as "baseline-dataset-calender.xlsx" but as I couldnt get the xcel package to work nicely I converted each project dataset into a csv file stored in the `./data/` folder.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(ggplot2)
library(readxl)
library(dplyr)

#I have tried to do this using excel but it is way too hard.
# datBASE1 <- readxl::read_excel("./data/Sem two planning.xlsx", sheet = c(3))
# datBASE2 <- readxl::read_excel("./data/Sem two planning.xlsx", sheet = c(4))
# datBASE3 <- readxl::read_excel("./data/Sem two planning.xlsx", sheet = c(5))
# read.csv("./data/")
# names(datBASE1)==names(datBASE2)
# names(datBASE2)==names(datBASE3)
# names(datBASE1)==names(datBASE3)
# str(datBASE1)
# str(datBASE2)
# str(datBASE1)
#### these are now as csv files for each datasheet entry
#orginal excel in Raw_data file...
#no conversion to csv to aviod same data issues...

datPhD <- readr::read_csv("./data/PhDProjects.csv") 
datCouncil <- readr::read_csv("./data/CouncilProjects.csv")
datInvert <- readr::read_csv("./data/InvertProjects.csv")

## Full tasks database
datBASE <- bind_rows(datPhD, datCouncil, datInvert) %>%
              filter(project != "NA")

# %>%
#               remove_missing()

# dplyr::bind_rows(datBASE1,datBASE2)

# DT::datatable(datBASE)
# 
# datBASE$startDate
# 
# names(datBASE)
```

#### Plot current data

```{r}
# names(datBASE)
# datBASE$project

ggplot(datBASE, aes(x = startDate, y = shortName)) +
  geom_point() + 
  facet_wrap(~project)
```

### `.xlsx`

These are excel workbooks. For now this is very simple and works with the current version of excel files (2020). Each "sheet" of the excel file contains a single projects information. This is then converted to a csv file when needed. In the future each project will have its own file that can be added to or modified in a shiny interactive web app.

```{r}
#excel read

#number of sheets in project currently


## Saved as csv's and imported as so below...
```

### `.csv`

Generally the data can be imported as a csv, or other form. 

```{r}
library(readr)
emailsCalender1 <- read_csv("data/anuemails.CSV")
#str(emailsCalender1)
```

### `.iCal` data

```{r}
#this currently online
```

### Other data