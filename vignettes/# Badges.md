# Badges

## Overview

## Post navigation

![Photo of badges on a bag](./8c9f280641d143efbe18d925de7abcb1) Posted August 29, 2017 by

[![Photo of badges on a bag](../_resources/0e79d60f66044e3696733699a3ee3bc2.jpg)](https://twitter.com/hildabast/status/779740990299144193)

I like badges – I have a lot of them! I’m also an open science advocate. So when a group of advocates declared their badges for authors were dramatically increasing open practice, I could have been a lock for the cheer squad. But, no, I’m not. In fact, I think the implications of the badge bandwagon are concerning.

These headlines and a tweeted claim will give you an idea of the level of hype around badges for sharing data and materials in science articles:

*Simple badge incentive could help eliminate bad science. ([**Ars Technica**](https://arstechnica.com/science/2016/05/achievement-unlocked-badges-induce-scientists-to-share-data/))*

*Digital badges motivate scientists to share data. ([**Nature**](http://www.nature.com/news/digital-badges-motivate-scientists-to-share-data-1.19907))*

*Even psychologists respond to meaningless rewards: All they needed to be more open with their data was a badge showing they did it. ([**FiveThirtyEight**](https://fivethirtyeight.com/features/even-psychologists-respond-to-meaningless-rewards/))*

*Data shows the effect of badges on transparency is unrivaled by any other known intervention. ([**Tweet**](https://twitter.com/uri_sohn/status/863558220635414534))*

That last one is a stunner, considering other known interventions include mandating data transparency as a condition for funding or publication! That tweet could take us straight to the issue of whether the badge policy pathway is ultimately good or bad for open science. And that a scientist said that goes to the peril of being a “true believer”. We’ll come back to those. But let’s start with the data people are talking about, and what these badges mean for us as readers.

The source of this was a paper by Mallory Kidwell and colleagues in [***PLOS Biology***](http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002456), called *“Badges to acknowledge open practices: a simple, low-cost, effective method for increasing transparency”*. The developer and prominent social marketer of the badges is the senior author of that paper and head of the organization tied to them, [**Brian Nosek**](http://projectimplicit.net/nosek/).

The title has most of the authors’ strong claims embedded in it. They are:

1.  The intervention studied is simply offering a badge if authors meet certain criteria.
2.  The intervention is *“low cost”*, *“low risk”*, *“relatively resource-lite”.*
3.  There are no other repercussions – *“if badges are not valued by authors, they are ignored and business continues as usual”*.
4.  Badges are “dramatically” effective – dramatic(ally) appears 9 times in the paper.
5.  Badges increase authors’ use of the kind of repository the badges exist in part to promote – like that of Nosek & co’s Open Science Framework ([**OSF**](https://osf.io/)).

The paper reports what seems to be the only study on this. It involves looking back at what happened before and after a prominent journal, *Psychological Science*, introduced badges in January 2014. To gauge whether any changes observed might be happening in the discipline anyway, the authors chose 4 journals that did not have badges for comparison.

They then collected data on open-ness of data and study materials from all 5 journals for research-based articles from 2012 to May 2015: 2 years of “before” data and 17 months of “after” data. Let’s look at the authors’ 5 claims and see whether the data support them. The open data for the project were a big help, so the authors get lots of brownie points for walking the open data talk.

![](../_resources/e7466cf957584c5f8830a6215fe14ee1.jpg)

## Claim 1: Was the intervention simple badges and criteria for them?

No. And that’s pivotal, because any effect could be because of co-intervention(s), not of badges alone.

The badges were among a set of changes at the journal in January 2014. And there is no way to pick apart the contribution of the badge, if anything else could affect the proportion of authors able or willing to share data and materials.

The badges paper does not mention the co-interventions, so you cannot rely on it to understand what they studied. They have no citation at all where they state the journal introduced badges. [**Here’s the journal editorial**](http://journals.sagepub.com/doi/full/10.1177/0956797613512465) that explains what happened from January 2014.

Badges were 1 of 5 initiatives introduced simultaneously. The initiatives were all directed at improved research reproducibility. They all had implications journal-side, and they all could have influenced authors’ decisions to go ahead and publish in *Psychological Science*, in ways that could affect the journal’s portfolio of research. Remember, to consider confounding variables, we’re looking for anything that could deter or incentivize publishing at the journal. Here are the 4 initiatives other than badges:

- Methods and results reporting were removed from the word limits, because of raised expectations for rigor and reporting quality.
- The evaluative criteria for editors and peer reviewers were changed, upping the importance of the description of methods and evaluating them stringently.
- 4 new items you have to detail and confirm were added on the article submission form, including confirming that you have reported all exclusions, that your manuscript reports all independent variables and manipulations you analyzed, and confirming your manuscript reports sample size calculation and data collection stopping rules.
- A move away from statistical significance, with expectation that analyses conform to what they call *“the new-statistics movement”* (with a tutorial for that). ([**Here’s my quick explainer**](http://blogs.plos.org/absolutely-maybe/2016/04/25/5-tips-for-avoiding-p-value-potholes/) on that issue.)

This represents a much more profound change on the editorial side than just adding a badge opportunity. And if the authors able and willing to do any of this, are associated with being an author who has data and materials in share-able state (including any required permissions), then the co-interventions and any interplay between them are potential contributors to any outcomes observed. Add to these interventions at the journal, the social marketing of the badges launch by influential open science advocates (ostensibly) independent of the journal.

To isolate the impact of badges, you would need groups that had the same conditions except the badges. One comparison group would then have compliance publicly shown only with words; another would have all the same criteria, but no public reward.

## Claim 2: Adding badges is low cost.

There was no data on this. The resource implications for journal staff and peer reviewers were not discussed. Some of the co-interventions appear resource-intensive for journals, both in establishment and implementation.

Then there’s the really big question: cost for authors, on whom the bulk of effort here lands. The badges-get-you-huge-bang-for-not-much-buck has become a major part of the social marketing strategy for open science, hasn’t it? Yet, high quality open data practice *is* a lot more effort than not.

The entire package, or even just the requirements to get a badge, would be resource-intensive for any authors who aren’t already open science practitioners and into what they call *“new statistics”*. And the impact of that probably lies at the heart of what we will look at under the next claim.

## Claim 3: There were no other repercussions.

To be clear, the authors definitely did not state there was an absence of other repercussions. They just seem to have assumed that there wouldn’t be, and didn’t report a plan for identifying unintended effects.

One issue jumped out with neon lights flashing and bells ringing as soon as I started looking at the data, though. It’s not in the paper, as absolute numbers are sparsely reported there. The paper focuses on percentages.

A part of why the percentage of articles reporting open data increased at *Psychological Science* (PS) was the denominator dropping: after January 2014, they published considerably fewer articles in total.

**Productivity: *Psychological Science* (red) & comparator journals publishing 2002 to 2016 (PubMed IDs)**

[![Chart showing journal records by year - see text for link to raw data](../_resources/c3191ab0cd0d47068f991b7942d9d6fb.jpg)](http://blogs.plos.org/absolutely-maybe/files/2017/08/Psych-Sci_articlesXyear.jpg)

*Purple arrow points to 2014, the first full year of new editorial policies at Psychological Science (PS)*

The data for this chart are [**here**](https://docs.google.com/spreadsheets/d/1u-j9ImcqxxXM-NzpOS2NojhH_xG1WFDV7cc5pVB-hd8/edit?usp=sharing). It doesn’t come from the badges study data. That’s for 2 reasons. The time period was too short – I couldn’t think about what the data might mean if I couldn’t see it in the context of longer trends, because the number of events per journal is so small. (There are only 3 comparator journals, because one didn’t start publishing till 2013. Note too that this is PubMed records, so it includes non-research items in journals.)

Journals in psychology were rocked by a crisis in 2011. That’s what spurred the intense interest in improved methods and reporting in this field. At *Psychological Science*, it turns out, after having retracted only 1 article ever before 2011, between 2011 and 2012 they retracted 9.

Secondly, the badges study counts the time of publication by inclusion in a “print issue” list of contents – not when the article was actually published (the e-published date). It was March 2014 before any post-2013 articles appeared, and May 2014 before the first badge was awarded. The basic trend is the same, either way. And the upshot is that in 2016, according to PubMed, PS was publishing far less than half the items it published the year before it introduced the new policies (from 363 to 145).

Why? Without more data on practice and policy at PS, there’s not much to go on. This would be consistent, though, with the new policies deterring authors who didn’t already practice open science. There wasn’t a major discipline-wide drop in article production. One of the competitor journals has overtaken PS, and new journals started.

Of course, with so many co-interventions, you can’t say it’s the badge-related criteria that reduced article production so much. But if you’re going to claim the benefits of more articles with shared data and materials, then you have to own the drop in journal productivity (and its potential implications) too.

## Claim 4: Adding badges alone is dramatically effective.

There is a lot I could say here, but I will limit it to a few key points. We’ve already seen some of those above: there are too many co-interventions to know what contribution badges made. And the increase in sharing without considering productivity exaggerates the impression of effectiveness.

It all suggests to me that the predominant effect we’re seeing here is a form of “natural selection”, with the journal ratcheting up its standards and possibly rejecting more, and its new systems potentially repelling less “open” authors. It would be really helpful to know what happened to submission and rejection rates at PS from 2010 onwards.

It seems from a superficial look at the data that the authors of 28% of the articles that qualified for badges apparently rejected the offer of the badge. If that is the case, this undercuts the badge as an incentive, too. The absolute number of badges was so small, though, and the timeframe so short, that all the data have a very high risk of [**bias**](https://www.ncbi.nlm.nih.gov/pubmedhealth/PMHT0030021/). (To help put it in perspective, the mean number of badges in the last 6 months of the study was 4.4 a month; the 6 months prior, it was 3.7.)

The methods of the study have a high risk of other forms of bias as well. For example, although the authors went to a lot of effort to make sure the different coders were in sync, there was only a single coder for each study. In my neck of the woods we would consider that a high risk of bias, especially coupled with not being blind to which journal articles came from.

The reporting also has a high degree of researcher spin, which always sets off alarm bells – like an abstract with no absolute numbers, and full text without showing proportions with absolute numbers.

The longer I looked at the data in this study and its context, the harder the impact of badges became to discern. And the relevance of this data to areas outside psychology was problematic too. Studies with no need for a data availability statement because all the data is in the paper and supplementary files can be common in some study types, for example.

It doesn’t mean of course that badges have no effects, especially when accompanied by intense marketing by opinion leaders. But interventions hyped from uncontrolled research generally speaking don’t turn out to be as “dramatic” as their proponents believe. And with funders increasing their requirements for open data, the waters here have been getting murkier.

[![Cartoon - A promising treatment is the larval stage of a disappointing one](../_resources/76067a45d19f470d9f95e95a554631c4.jpg)](http://statistically-funny.blogspot.com/2012/06/promising-over-hyped-under-tested.html)

## Claim 5: Adding badges increases use of independent repositories.

This is part of the intent of the intervention, designed, as it was, by an independent repository group. I didn’t look at the data on this question. Let’s just assume it achieves this aim as they say it does. And move on to what all this means – for us as readers, and for open science.

It was encountering these badges as a reader recently at *Psychological Science* that propelled me into writing this post. The marketing hype from advocates had disturbed me ever since this clearly weak study came out. But it coalesced into concern seeing it in action, and engaging with the badge group on Twitter about it.

Here’s what the article in question looked like at home:

![Open badges at PS on a closed access article](../_resources/049bc3d0b6fd4eabbaa88d0da932a7ec.jpg)

Open data badge, open materials badge – on a closed access article. (The open data wasn’t included as supplementary material and nor was there a link to it outside the paywall. To their credit, they are going to try to organize accessible links in response my complaint.)

Here’s what the article looked like at work, where we have a subscription to the journal:

![Open badges at PS ](../_resources/f7ffdf9b1c6b44d299623a961ba8e1e9.jpg)

For anyone with a subscription viewing this, there will be the impression that these authors are practicing fully open science. They are not.

The Twitter conversation about why the open data/materials badges are so limited, ended up with the argument, it’s so high impact closed journals can say they have/move to more open practices – and that access to articles isn’t a problem for open science.

I don’t think the argument that an article is not part of a study’s data flies. It’s as though we’ve moved from saying the paper *is* the study, to the paper isn’t even *part* of the study! And open, for data and materials, is defined here in such a way that you can leave essential data and methodological information behind the paywall – and still gain open practice badges.

![Cartoon Sorta-Kinda-Open badge](../_resources/3dfa40bb726f4de6a659f82c0afd1340.jpg)

Part of the reason for openness of studies’ artifacts is to enable critical appraisal – the kind I just did. And not only from people with subscriptions.

Sometimes, you understand more from a study’s data than the paper – if you have the time and skills. But usually, you need as many artifacts as you can get. What’s more, if the authors stick to the specific criteria needed to get an open badge, then they can leave out data they didn’t analyze for the paper but which is essential to check on their analytical choices and interpretations.

Funders’ open data requirements aren’t so limited, and that matters. A large part of what the people who use data from others’ previous studies are studying has nothing to do with the authors’ original analyses. In [**this analysis**](http://www.nejm.org/doi/full/10.1056/NEJMsa1603542#t=article), over 70% of requests for clinical data from a repository giving a reason was, asking new questions.

One of the most compelling talks I’ve ever heard about open-ness was by Audrey Watters, [**at Open Con 2014**](http://hackeducation.com/2014/11/16/from-open-to-justice). (Check out the blog post at that link even if not the full talk.) She eloquently spelled out the dangers of openwashing. A bit like people prominently badging high sugar foods as “low fat”.

![Audrey Watters' definition of openwashing - see link in the text](../_resources/bdff379d574148819f977b0524d98bbb.jpg)

The version of data and materials sharing attached to the open badges isn’t the only path here. There are funders’ mandates and Dryad’s Joint Data Archiving Policy ([**JDAP**](http://datadryad.org/pages/jdap)) that encourage more open routes, for example. These practices and fully open journals have been growing without badges (see [**here**](https://arxiv.org/abs/1301.3744), [**here**](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0018657), [**here**](http://www.emeraldinsight.com/doi/abs/10.1108/AJIM-09-2016-0159?fullSc=1&journalCode=ajim), [**here**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640582/)), sometimes at vastly higher rates than in PS.

It’s an open question, really, whether [**the spread**](https://osf.io/tvyxz/wiki/5.%20Adoptions%20and%20Endorsements/) of this badges brand will be a net gain or loss for open-ness in science. What if it spreads at the expense of more effective and open pathways? People who want to be open practitioners, but need to publish some things in high impact closed journals could do better for others by trying those that accept their work after it’s posted as a preprint with open data, rather than seeking out badges.

Here’s another from my personal badge collection. It’s pinned next to my computer at work. It’s an important one.

<img width="250" height="236" src="../_resources/0906c59c0e0246079c9df8012db57542.jpg"/>

“Am I fired yet?” is one of several reminders to myself to put principles and public interest ahead of my personal interest. I learned, painfully, decades ago, that there is a strongly magnetic pull towards your personal interests. I learned it in advocacy movements. It’s not only commercial interest that’s a risk. You truly need to minimize bias in your approach to evidence, or you are lost.

As I’ve spent time with the badges “magic bullet” – simple! cheap! no side effects! dramatic benefits! – supported by a single uncontrolled study by an influential opinion leader, with a biased design in a narrow unrepresentative context, very small number of events, and short timeframe….I’ve come to think its biggest lesson may be that even many open science advocates have yet to fully absorb the implications of science’s reliability problems.

*Continued on 31 August – FAQ with more data….[**What’s Open, What’s Data? What’s Proof, What’s Spin?**](http://blogs.plos.org/absolutely-maybe/2017/09/01/whats-open-whats-data-whats-proof-whats-spin/)*

*Follow-up post on 30 December 2019 – [**Open Badges Redux: A Few Years On, How’s the Evidence Looking?**](https://blogs.plos.org/absolutely-maybe/2019/12/30/open-badges-redux-a-few-years-on-hows-the-evidence-looking/)*

![Cartoon - the biggest bias we have to deal with is our own](../_resources/bde0c0ba65314508908f81a269de93ec.jpg)

*\[Update, 30 August 2017\]* [**Comment posted at PubMed Commons**](https://hypothes.is/a/KWZypH5BEeiPN-sf54-pVQ). *\[Update, 29 December 2019\]* PubMed Commons link updated with archived version at Hypothesis. The authors, although notified of this comment, never replied.

~~~~

***Disclosures: **My day job is with a public agency that maintains major literature and data repositories (National Center for Biotechnology Information at the National Library of Medicine/National Institutes of Health). I have had a long relationship with PLOS, including several years as an academic editor of* PLOS Medicine*, and serving in the human ethics advisory group of* PLOS One*, as well as blogging here at its Blog Network. [**I am a user**](https://osf.io/6gj8t/) of the Open Science Framework.*

**The cartoons and photo of badges (on my bag and wall at work) are my own **[(CC-NC-ND-SA](http://creativecommons.org/licenses/by-nc-nd/4.0/)*****[license)](http://creativecommons.org/licenses/by-nc-nd/4.0/)**.(More cartoons at ****[Statistically Funny](http://statistically-funny.blogspot.com/) **and on [**Tumblr**](http://sci-med-cartoonery.tumblr.com/).)*

*\* The thoughts Hilda Bastian expresses here at *[**Absolutely Maybe**](http://blogs.scientificamerican.com/absolutely-maybe/)* are personal, and do not necessarily reflect the views of the National Institutes of Health or the U.S. Department of Health and Human Services.*

## Post navigation

![](https://secure.gravatar.com/avatar/b7cccea0f2a6ef54318ec7ce197a438f?s=100&d=blank&r=g)
~~~~



## Background

Efficient programming is an important and skill for generating the correct result, on time. Yet coding is only one part of a wider skillset needed for successful outcomes for projects involving R programming. Unless your project is to write generic R code (i.e. unless you are on the R Core Team), the project will probably transcend the confines of the R world: it must engage with a whole range of other factors. In this context we define ‘workflow’ as the sum of practices, habits and systems that enable productivity.<a id="fnref8"></a>[8](#fn8) To some extent workflow is about personal preferences. Everyone’s mind works differently so the most appropriate workflow varies from person to person and from one project to the next. Project management practices will also vary depending the scale and type of the project: it’s a big topic but can usefully be condensed in 5 top tips.

## Top 5 tips for efficient workflow

- Start without writing code but with a clear mind and perhaps a pen and paper. This will ensure you keep your objectives at the forefront of your mind, without getting lost in the technology.
  
- Make a plan. The size and nature will depend on the project but time-lines, resources and ‘chunking’ the work will make you more effective when you start.
  
- Select the packages you will use for implementing the plan early. Minutes spent researching and selecting from the available options could save hours in the future.
  
- Document your work at every stage: work can only be effective if it’s communicated clearly and code can only be efficiently understood if it’s commented.
  
- Make your entire workflow as reproducible as possible. **knitr** can help with this in the phase of documentation.
  

## A project planning typology

Appropriate project management structures and workflow depend on the *type* of project you are undertaking. The typology below demonstrate the links between project type and project management requirements.<a id="fnref9"></a>[9](#fn9)

- *Data analysis*. Here you are trying to explore datasets to discover something interesting/answer some questions. The emphasis is on speed of manipulating your data to generate interest results. Formality is less important in this type of project. Sometimes this analysis project may only be part of a larger project (the data may have to be created in a lab, for example). How the data analysts interact with the rest of the team may be as important for the project’s success as how they interact with each other.
- *Package creation*. Here you want to create code that can be reused across projects, possibly by people whose use case you don’t know (if you make it publicly available). The emphasis in this case will be on clarity of user interface and documentation, meaning style and code review are important. Robustness and testing are important in this type of project too.
- *Reporting and publishing*. Here you are writing a report or journal paper or book. The level of formality varies depending upon the audience, but you have additional worries like how much code it takes to arrive at the conclusions, and how much output does the code create.
- *Software applications*. This could range from a simple Shiny app to R being embedded in the server of a much larger piece of software. Either way, since there is limited opportunity for human interaction, the emphasis is on robust code and gracefully dealing with failure.

Based on these observations we recommend thinking about the type of workflow, file structure and project management system suits your projects best. Sometimes it’s best not to be prescriptive so we recommend trying different working practices to discover which works best, time permitting.<a id="fnref10"></a>[10](#fn10)

There are, however, concrete steps that can be taken to improve workflow in most projects that involve R programming. Learning them will, in the long-run, improve productivity and reproducibility. With these motivations in mind, the purpose of this chapter is simple: to highlight some key ingredients of an efficient R workflow. It builds on the concept of an R/RStudio *project*, introduced in Chapter 2, and is ordered chronologically throughout the stages involved in a typical project’s lifespan, from its inception to publication:

- Project planning. This should happen before any code has been written, to avoid time wasted using a mistaken analysis strategy. Project management is the art of making project plans happen.
  
- Package selection. After planning your project you should identify which packages are most suitable to get the work done quickly and effectively. With rapid increases in the number and performance of packages. `*_join` from **dplyr**, for example, is often more appropriate than `merge`, as we’ll see in [6](https://csgillespie.github.io/efficientR/efficient-data-carpentry.html#efficient-data-carpentry). It is therefore more important than ever to consider the range of options at the outset.
  
- Publication. This final stage is relevant if you want your R code to be useful for others in the long term. To this end Section [4.5](https://csgillespie.github.io/efficientR/efficient-workflow.html#publication) touches on documentation using knitr and the much stricter approach to code publication of package development.
  

## Project planning and management

Good programmers working on a complex project will rarely just start typing code. Instead, they will plan the steps needed to complete the task as efficiently as possible: “smart preparation minimizes work” (Berkun [2005](#ref-berkun2005art)). Although search engines are useful for identifying the appropriate strategy, trail-and-error approaches (for example typing code at random and Googling the inevitable error messages) are usually highly *inefficient*.

Strategic thinking especially important during a project’s inception: if you make a bad decision early on, it will have cascading negative impacts throughout the project’s entire lifespan. So detrimental and ubiquitous is this phenomenon in software development that a term has been coined to describe it: *technical debt*. This has been defined as “not quite right code which we postpone making it right” (Kruchten, Nord, and Ozkaya [2012](#ref-kruchten2012technical)). Dozens of academic papers have been written on the subject but, from the perspective of *beginning* a project (i.e. in the planning stage, where we are now), all you need to know is that it is absolutely vital to make sensible decisions at the outset. If you do not, your project may be doomed to failure of incessant rounds of refactoring (we return to the topic of refactoring in Chapter [9](https://csgillespie.github.io/efficientR/efficient-collaboration.html#efficient-collaboration)).

To minimise technical debt at the outset, the best place to start may be with a pen and paper and an open mind. Sketching out your ideas and deciding precisely what you want to do, free from the constraints of a particular piece of technology, can be rewarding exercise before you begin. Project planning and ‘visioning’ can be a creative process not always well-suited to the linear logic of computing, despite recent advances in project management software, some of which are outlined in the bullet points below.

Scale can loosely be defined as the number of people working on a project. It should be considered at the outset because the importance of project management increases exponentially with the number of people involved. Project management may be trivial for a small project but if you expect it to grow, implementing a structured workflow early could avoid problems later. On small projects consisting of a ‘one off’ script, project management may be a distracting waste of time. Large projects involving dozens of people, on the other hand, require much effort dedicated to project management: regular meetings, division of labour and a scalable project management system to track progress, issues and priorities will inevitably consume a large proportion of the project’s time. Fortunately a multitude of dedicated project management systems have been developed to cater for projects across a range of scales. These include, in rough ascending order of scale and complexity:

- the interactive code sharing site [GitHub](https://github.com/), which is described in more detail in Chapter [9](https://csgillespie.github.io/efficientR/efficient-collaboration.html#efficient-collaboration))
  
- [ZenHub](https://www.zenhub.io/), a browser plugin that is “the first and only project management suite that works natively within GitHub”
  
- web-based and easy-to-use tools such as [Trello](https://trello.com/)
  
- Dedicated desktop project management software such as [ProjectLibre](http://sourceforge.net/projects/projectlibre/) and [GanttProject](http://sourceforge.net/projects/projectlibre/)
  
- fully featured, enterprise scale open source project management systems such as [OpenProject](https://www.openproject.org/) and [redmine](http://www.redmine.org/).
  

Regardless of the software (or lack thereof) used for project management, it involves considering the project’s aims in the context of available resources (e.g. computational and programmer resources), project scope, time-scales and suitable software. And these things should be considered together. To take one example, is it worth the investment of time needed to learn a particular R package which is not essential to completing the project but which will make the code run faster? Does it make more sense to hire another programmer or invest in more computational resources to complete an urgent deadline?

Minutes spent thinking through such issues before writing a single line can save hours in the future. This is emphasised in books such as Berkun ([2005](#ref-berkun2005art)) and PMBoK ([2000](#ref-PMBoK2000)) and useful online resources such those by [teamgantt.com](http://teamgantt.com/guide-to-project-management/) and [lasa.org.uk](http://www.lasa.org.uk/uploads/publications/ictpublications/computanews_guides/lcgpm.pdf), which focus exclusively on project planning. This section condenses some of the most important lessons from this literature in the context of typical R projects (i.e. which involve data analysis, modelling and visualisation).

### ‘Chunking’ your work

Once a project overview has been devised and stored, in mind (for small projects, if you trust that as storage medium!) or written, a plan with a time-line can be drawn-up. The up-to-date visualisation of this plan can be a powerful reminder to yourself and collaborators of progress on the project so far. More importantly the timeline provides an overview of what needs to be done next. Setting start dates and deadlines for each task will help prioritise the work and ensure you are on track. Breaking a large project into smaller chunks is highly recommended, making huge, complex tasks more achievable and modular PMBoK ([2000](#ref-PMBoK2000)). ‘Chunking’ the work will also make collaboration easier, as we shall see in Chapter 5.

<img width="539" height="359" src="../_resources/e3af8d168f3646ff93c0894eea5f7a8b.png"/>

Figure 4.1: Schematic illustrations of key project phases and levels of activity over time, based on PMBoK ([2000](#ref-PMBoK2000)).

The tasks that a project should be split into will depend the nature of the work and the phases illustrated in Figure [4.1](https://csgillespie.github.io/efficientR/efficient-workflow.html#fig:4-1) represent a rough starting point, not a template and the ‘programming’ phase will usually need to be split into at least ‘data tidying’, ‘processing’, and ‘visualisation’.

### Making your workflow SMART

A more rigorous (but potentially onerous) way to project plan is to divide the work into a series of objectives and tracking their progress throughout the project’s duration. One way to check if an objective is appropriate for action and review is by using the SMART criteria.

- Specific: is the objective clearly defined and self-contained?
- Measurable: is there a clear indication of its completion?
- Attainable: can the target be achieved?
- Realistic: have sufficient resources been allocated to the task?
- Time-bound: is there an associated completion date or milestone?

If the answer to each of these questions is ‘yes’, the task is likely to be suitable to include in the project’s plan. Note that this does not mean all project plans need to be uniform. A project plan can take many forms, including a short document, a Gantt chart (see Figure [4.2](https://csgillespie.github.io/efficientR/efficient-workflow.html#fig:4-2) or simply a clear vision of the project’s steps in mind.

<img width="616" height="435" src="../_resources/f3f0b8990e404ad08f8310e481bbe4bf.png"/>

Figure 4.2: A Gantt chart created using **DiagrammeR** illustrating the steps needed to complete this book at an early stage of its development.

### Visualising plans with R

Various R packages can help visualise the project plan. While these are useful, they cannot compete with the dedicated project management software outlined at the outset of this section. However, if you are working on relatively simple project, it is useful to know that R can help represent and keep track of your work. Packages for plotting project progress include:<a id="fnref11"></a>[11](#fn11)

- the [**plan**](https://cran.r-project.org/web/packages/plan/) package, which provides basic tools to create burndown charts (which concisely show whether a project is on-time or not) and Gantt charts.
  
- [**plotrix**](https://cran.r-project.org/web/packages/plotrix/index.html), a general purpose plotting package, provides basic Gantt chart plotting functionality. Enter `example(gantt.chart)` for details.
  
- [**DiagrammeR**](http://rich-iannone.github.io/DiagrammeR/), a new package for creating network graphs and other schematic diagrams in R. This package provides an R interface to simple flow-chart file formats such as [mermaid](https://github.com/knsv/mermaid) and [GraphViz](https://github.com/ellson/graphviz).
  

The small example below (which provides the basis for creating charts like Figure [4.2](https://csgillespie.github.io/efficientR/efficient-workflow.html#fig:4-2) illustrates how **DiagrammeR** can take simple text inputs to create informative up-to-date Gantt charts. Such charts can greatly help with the planning and task management of long and complex R projects, as long as they do not take away valuable programming time from core project objectives. {#DiagrammeR}

```
library("DiagrammeR")
# Define the Gantt chart and plot the result (not shown)
mermaid("gantt
        Section Initiation
        Planning           :a1, 2016-01-01, 10d
        Data processing    :after a1  , 30d")
```

In the above code `gantt` defines the subsequent data layout. `Section` refers to the project’s section (useful for large projects, with milestones) and each new line refers to a discrete task. `Planning`, for example, has the code `a`, begins on the first day of 2016 and lasts for 10 days. See [knsv.github.io/mermaid/gantt.html](http://knsv.github.io/mermaid/gantt.html) for more detailed documentation.

#### Exercises

1.  What are the three most important work ‘chunks’ of your current R project?
    
2.  What is the meaning of ‘SMART’ objectives (see [Making your workflow SMART](https://csgillespie.github.io/efficientR/efficient-workflow.html#smart)).
    
3.  Run the [code chunk](#DiagrammeR) at the end of this section to see the output.
    
4.  Bonus exercise: modify this code to create a basic Gantt chart of an R project you are working on.
    

## Package selection

A good example of the importance of prior planning to minimise effort and reduce technical debt is package selection. An inefficient, poorly supported or simply outdated package can waste hours. When a more appropriate alternative is available this waste can be prevented by prior planning. There are many poor packages on CRAN and much duplication so it’s easy to go wrong. Just because a certain package *can* solve a particular problem, doesn’t mean that it *should*.

Used well, however, packages can greatly improve productivity: not reinventing the wheel is part of the ethos of open source software. If someone has already solved a particular technical problem, you don’t have to re-write their code, allowing you to focus on solving the applied problem. Furthermore, because R packages are generally (but not always) written by competent programmers and subject to user feedback, they may work faster and more effectively that the hastily prepared code you may have written. All R code is open source and potentially subject to peer review. A prerequisite of publishing an R package is that developer contact details must be provided, and many packages provide a site for issue tracking. Furthermore, R packages can increase programmer productivity by dramatically reducing the amount of code they need to write because all the code is *packaged* in functions behind the scenes.

Let’s take an example. Imagine for a project you would like to find the distance between sets of points (origins, `o` and destinations, `d`) on the Earth’s surface. Background reading shows that a good approximation of ‘great circle’ distance, which accounts for the curvature of the Earth, can be made by using the Haversine formula, which you duly implement, involving much trial and error:

```
# Function to convert degrees to radians
deg2rad = function(deg) return(deg*pi/180)

# Create origins and destinations
o = c(lon = -1.55, lat = 53.80)
d = c(lon = -1.61, lat = 54.98)

# Convert to radians
o_rad = deg2rad(o)
d_rad = deg2rad(d)

# Find difference in degrees
delta_lon = (o_rad[1] - d_rad[1])
delta_lat = (o_rad[2] - d_rad[2])

# Calculate distance with Haversine formula
a = sin(delta_lat / 2)^2 + cos(o_rad[2]) * cos(d_rad[2]) * sin(delta_lon / 2)^2
c = 2 * asin(min(1, sqrt(a)))
(d_hav1 = 6371 * c) # multiply by Earth's diameter
#> [1] 131
```

This method works but it takes time to write, test and debug. Much better to package it up into a function. Or even better, use a function that someone else has written and put in a package:

```
# Find great circle distance with geosphere
(d_hav2 = geosphere::distHaversine(o, d))
#> [1] 131415
```

The difference between the hard-coded method and the package method is striking. One is 7 lines of tricky R code involving many subetting stages and small, similar functions (e.g. `sin` and `asin`) which are easy to confuse. The other is one line of simple code. The package method using **geosphere** took perhaps 100th of the time *and* gave a more accurate result (because it uses a more accurate estimate of the diameter of the Earth). This means that a couple of minutes searching for a package to estimate great circle distances would have been time well spent at the outset of this project. But how do you search for packages?

### Searching for R packages

Building on the example above, how can on find out if there is a package to solve your particular problem? The first stage is to guess: if it is a common problem, someone has probably tried to solve it. The second stage is to search. A simple Google query, `haversine formula R`, returned a link to the **geosphere** package in the second result (a [hardcoded implementation](http://www.r-bloggers.com/great-circle-distance-calculations-in-r/) was first).

Beyond Google, there are also several sites for searching for packages and functions. [rdocumentation.org](http://www.rdocumentation.org/) provides a multi-field search environmnet to pinpoint the function or package you need. Amazingly, the search for `haversine` in the Description field yielded 10 results from 8 packages: R has at least *8* implementations of the Haversine formula! This shows the importance of careful package selection as there are often many packages that do the same job, as we see in the next section. There is also a way to find the function from within R, with `RSiteSearch()`, which opens a url in your browser linking to a number of functions (40) and vignettes (2) that mention the text string:

```
# Search CRAN for mentions of haversine
RSiteSearch("haversine")
```

### How to select a package

Due to the conservative nature of base R development, which rightly prioritises stability over innovation, much of the innovation and performance gains in the ‘R ecosystem’ has occurred in recent years in the packages. The increased ease of package development (H. Wickham [2015](#ref-Wickham_2015)[c](#ref-Wickham_2015)) and interfacing with other languages (e.g. Eddelbuettel et al. [2011](#ref-Eddelbuettel_2011)) has accelerated their number, quality and efficiency. An additional factor has been the growth in collaboration and peer review in package development, driven by code-sharing websites such as GitHub and online communities such as [ROpenSci](https://ropensci.org/) for peer reviewing code.

Performance, stability and ease of use should be high on the priority list when choosing which package to use. Another more subtle factor is that some packages work better together than others. The ‘R package ecosystem’ is composed of interrelated package. Knowing something of these inter-dependencies can help select a ‘package suite’ when the project demands a number of diverse yet interrelated programming tasks. The ‘hadleyverse’, for example, contains many interrelated packages that work well together, such as **readr**, **tidyr**, and **dplyr**.<a id="fnref12"></a>[12](#fn12) These may be used together to read-in, tidy and then process the data, as outlined in the subsequent sections.

There is no ‘hard and fast’ rule about which package you should use and new packages are emerging all the time. The ultimate test will be empirical evidence: does it get the job done on your data? However, the following criteria should provide a good indication of whether a package is worth an investment of your precious time, or even installing on your computer:

- **Is it mature?** The more time a package is available, the more time it will have for obvious bugs to be ironed out. The age of a package on CRAN can be seen from its Archive page on CRAN. We can see from [cran.r-project.org/src/contrib/Archive/ggplot2/](https://cran.r-project.org/src/contrib/Archive/ggplot2/), for example, that **ggplot2** was first released on the 10th June 2007 and that it has had 28 releases. The most recent of these at the time of writing was **ggplot2** 2.0.0: reaching 1 or 2 in the first digit of package versions is usually an indication from the package author that the package has reached a high level of stability.
  
- **Is it actively developed?** It is a good sign if packages are frequently updated. A frequently updated package will have its latest version ‘published’ recently on CRAN. The CRAN package page for **ggplot2**, for example, said `Published: 2015-12-18`, less than a month old at the time of writing.
  
- **Is it well documented?** This is not only an indication of how much thought, care and attention has gone into the package. It also has a direct impact on its ease of use. Using a poorly documented package can be inefficient due to the hours spent trying to work out how to use it! To check if the package is well documented, look at the help pages associated with its key functions (e.g. `?ggplot`), try the examples (e.g. `example(ggplot)`) and search for package vignettes (e.g. `vignette(package = "ggplot2")`).
  
- **Is it well used?** This can be seen by searching for the package name online. Most packages that have a strong user base will produce thousands of results when typed into a generic search engine such as Google’s. More specific (and potentially useful) indications of use will narrow down the search to particular users. A package widely used by the programming community will likely visible GitHub. At the time of writing a search for [**ggplot2**](https://github.com/search?utf8=%E2%9C%93&q=ggplot2) on GitHub yielded over 400 repositories and almost 200,000 matches in committed code! Likewise, a package that has been adopted for use in academia will tend to be mentioned in Google Scholar (again, **ggplot2** scores extremely well in this measure, with over 5000 hits).
  

An article in [simplystats](http://simplystatistics.org/2015/11/06/how-i-decide-when-to-trust-an-r-package/) discusses this issue with reference to the proliferation of GitHub packages (those that are not available on CRAN). In this context well-regarded and experienced package creators and ‘indirect data’ such as amount of GitHub activity are also highlighted as reasons to trust a package.

The websites of [MRAN](https://mran.revolutionanalytics.com/packages) and [METACRAN](http://www.r-pkg.org/) can help the package selection process by providing further information on each package uploaded to CRAN. [METACRAN](http://www.r-pkg.org/), for example, provides metadata about R packages via a simple API and the provision of ‘badges’ to show how many downloads a particular package has per month. Returning to the Haversine example above, we could find out how many times two packages that implement the formula are downloaded each month with the following urls:

- `http://cranlogs.r-pkg.org/badges/last-month/geosphere`, downloads of **geosphere**:

<img width="193" height="26" src="../_resources/b5de72fb2ee14738baab946c57b59bbc.png"/>

- `http://cranlogs.r-pkg.org/badges/last-month/geoPlot`, downloads of **geoPlot**:

<img width="193" height="26" src="../_resources/c34fd720365b4485ad6dbc8cfba1c56c.png"/>

It is clear from the results reported above that **geosphere** is by far the more popular package, so is a sensible and mature choice for dealing with distances on the Earth’s surface.

## Publication

The final stage in a typical project workflow is publication. Although it’s the final stage to be worked on, that does not mean you should only document *after* the other stages are complete: making documentation integral to your overall workflow will make this stage much easier and more efficient.

Whether the final output is a report containing graphics produced by R, an online platform for exploring results or well-documented code that colleagues can use to improve their workflow, starting it early is a good plan. In every case the programming principles of reproducibility, modularity and DRY (don’t repeat yourself) discussed in Chapter [3](https://csgillespie.github.io/efficientR/programming.html#programming) will make your publications faster to write, easier to maintain and more useful to others.

Instead of attempting a comprehensive treatment of the topic we will touch briefly on a couple of ways of documenting your work in R: dynamic reports and R packages. There is a wealth of material on each of these online. A wealth of online resources exists on each of these; to avoid duplication of effort the focus is on documentation from a workflow efficiency perspective.

### Dynamic documents with knitr

When writing a report using R outputs a typical workflow has historically been to 1) do the analysis 2) save the resulting graphics and record the main results outside the R project and 3) open a program unrelated to R such as LibreOffice to import and communicate the results in prose. This is inefficient: it makes updating and maintaining the outputs difficult (when the data changes, steps 1 to 3 will have to be done again) and there is an overhead involved in jumping between incompatible computing environments.

To overcome this inefficiency in the documentation of R outputs the **knitr** package was developed. Used in conjunction with RStudio and building on a version of Markdown that accepts R code (RMarkdown, saved as .Rmd files) **knitr** allows for documents to be generated automatically. Furthermore, *nothing* is efficient unless you can quickly redo it. Documenting your code inside dynamic documents in this ways ensures that this is the case.

This not briefly explains RMarkdown for the un-initiated. RMarkdown is a form of Markdown. Markdown is a pure text document format that has become a standard for documentation for software. It is the default format for displaying text on GitHub. RMarkdown allows the user to embed R code in a Markdown document. This is a powerful addition to Markdown, as it allows custom images, tables and even interactive visualisations, to be included in your R documents. RMarkdown is an efficient file format to write in because it is light-weight, human and computer readable, and is much less verbose than HTML, LaTeX. This book was written in RMarkdown.

Results are generated *on the fly* by including ‘code chunks’ such as that illustrated below:

```
​```r
(1:5)^2
#> [1]  1  4  9 16 25
```
```

This code, will result in the following output when the RMarkdown document is compiled:

```
(1:5)^2
#> [1]  1  4  9 16 25
```

The resulting output is evaluated each time the document is compiled. To tell **knitr** that `(1:5)^2` is R code that needs to be evaluated, it must by preceded by ` ```{r}` on the line before the R code, and ` ``` ` at the end of the chunk. When you adapt to this workflow it is highly efficient, especially as RStudio provides a number of shortcuts that make it easy to create and modify code chunks. To create a chunk while editing a .Rmd file, for example, simply enter `Ctrl+Alt+I` on Windows or Linux or select the option from the Code dropdown menu.

Once your document has compiled it should appear on your screen into the file format requested. If a html file has been generated (as is the default), RStudio provides a feature that allows you to put it up online rapidly. This is done using the [rpubs](https://rpubs.com/) website, a store of a huge number of dynamic documents (which could be a good source of inspiration for your publications). Assuming you have an RStudio account, clicking the ‘Publish’ button at the top of the html output window will instantly publish your work online, with a minimum of effort, enabling fast and efficient communication with many collaborators and the public.

An important advantage of dynamically documenting work this way is that when the data or analysis code changes, the results will be updated in the document automatically. This can save hours of fiddly copying and pasting of R output between different programs. Also, if your client wants pages and pages of documented output, **knitr** can provide them with a minimum of typing, e.g. by creating slightly different versions of the same plot over and over again. From a delivery of content perspective, that is certainly an efficiency gain compared with hours of copying and pasting figures!

If your RMarkdown documents include time-consuming processing stages, a speed boost can be attained after the first build by setting `opts_chunk$set(cache = TRUE)` in the first chunk of the document. This setting was used to reduce the build times of this book, as can be seen on [GitHub](https://github.com/csgillespie/efficientR/blob/master/code/before_script.R).

Furthermore dynamic documents written in RMarkdown can compile into a range of output formats including html, pdf and Microsoft’s docx. There is a wealth of information on the details of dynamic report writing that is not worth replicating here. Key references are RStudio’s excellent website on RMarkdown hosted at [rmarkdown.rstudio.com/](http://rmarkdown.rstudio.com/) and, for a more detailed account of dynamic documents with R, (Xie [2015](#ref-xie2015dynamic)).

### R packages

A strict approach to project management and workflow is treating your projects as R packages. This approach has advantages and limitations. The major risk with treating a project as a package is that the package is quite a strict way of organising work. Packages are suited for code intensive projects where code documentation is important. An intermediate approach is to use a ‘dummy package’ that includes a DESCRIPTION file in the root directory telling users of the project which packages must be installed for the code to work. This book is based on a dummy package so that we can easily keep the dependencies up-to-date (see the book’s [DESCRIPTION](https://github.com/csgillespie/efficientR/blob/master/DESCRIPTION) file online for an insight into how this works).

Creating packages is good practice in terms of learning to correctly document your code, store example data, and even (via vignettes) ensure reproducibility. But it can take a lot of extra time so should not be taken lightly. This approach to R workflow is appropriate for managing complex projects which repeatedly use the same routines which can be converted into functions. Creating project packages can provide foundation for generalising your code for use by others, e.g. via publication on GitHub or CRAN. And R package development has been made much easier in recent years by the development of the **devools** package, which is highly recommended for anyone attempting to write an R package.

The number of essential elements of R packages differentiate them from other R projects. Three of these are outlined below from an efficiency perspective.

- The [`DESCRIPTION`](http://r-pkgs.had.co.nz/description.html) file contains key information about the package, including which packages are required for the code contained in your package to work, e.g. using `Imports:`. This is efficient because it means that anyone who installs your package will automatically install the other packages that it depends on.
    
- The `R/` folder contains all the R code that defines your package’s functions. Placing your code in a single place and encouraging you to make your code modular in this way can greatly reduce duplication of code on large projects. Furthermore the documentation of R packages through [Roxygen tags](http://r-pkgs.had.co.nz/man.html#man-workflow) such as `#' This function does this...` makes it easy for others to use your work. This form of efficient documentation is facilitated by the **roxygen2** package.
    
- The `data/` folder contains example code for demonstrating to others how the functions work and transporting datasets that will be frequently used in your workflow. Data can be added automatically to your package project using the **devtools** package, with `devtools::use_data()`. This can increase efficiency by providing a way of distributing small to medium sized datasets and making them available when the package is loaded with the function `data('data_set_name')`.
    

The package **testthat** makes it easier than ever to test your R code as you go, ensuring that nothing breaks. This, combined with ‘continuous integration’ services, such as that provided by Travis, make updating your code base as efficient and robust as possible. This, and more, is described in (Cotton [2016](#ref-cotton_testing_2016)[b](#ref-cotton_testing_2016)).

As with dynamic documents, package development is a large topic. For small ‘one-off’ projects the time taken in learning how to set-up a package may not be worth the savings. However packages provide a rigorous way of storing code, data and documentation that can greatly boost productivity in the long-run. For more on R packages see (H. Wickham [2015](#ref-Wickham_2015)[c](#ref-Wickham_2015)): the online version provides all you need to know about writing R packages for free (see [r-pkgs.had.co.nz/](http://r-pkgs.had.co.nz/)).

### References

Berkun, Scott. 2005. *The Art of Project Management*. O’Reilly Media.

Kruchten, Philippe, Robert L Nord, and Ipek Ozkaya. 2012. “Technical Debt: From Metaphor to Theory and Practice.” *IEEE Software*, no. 6. IEEE: 18–21.

PMBoK, A. 2000. “Guide to the Project Management Body of Knowledge.” *Project Management Institute, Pennsylvania USA*.

Wickham, Hadley. 2015c. *R Packages*. O’Reilly Media.

Eddelbuettel, Dirk, Romain François, J. Allaire, John Chambers, Douglas Bates, and Kevin Ushey. 2011. “Rcpp: Seamless R and C++ Integration.” *Journal of Statistical Software* 40 (8): 1–18.

Xie, Yihui. 2015. *Dynamic Documents with R and Knitr*. Vol. 29. CRC Press.

Cotton, Richard. 2016b. *Testing R Code*.
```



#### Pocket - Search : badges

[B](https://getpocket.com/redirect?url=https%3A%2F%2Fbadgr.com%2Fpublic%2Fbadges%2FfIkT1C0_Txu7-xyIOSroTw)

[Badgr](https://getpocket.com/redirect?url=https%3A%2F%2Fbadgr.com%2Fpublic%2Fbadges%2FfIkT1C0_Txu7-xyIOSroTw)

[badgr.com](https://getpocket.com/redirect?url=https%3A%2F%2Fbadgr.com%2Fpublic%2Fbadges%2FfIkT1C0_Txu7-xyIOSroTw)

[](https://app.getpocket.com/read/1285995252)

[Badges to Acknowledge Open Practices: A Simple, Low-Cost, Effective Method for Increasing Transparency](https://app.getpocket.com/read/1285995252)

[PLOS](https://getpocket.com/redirect?url=https%3A%2F%2Fjournals.plos.org%2Fplosbiology%2Farticle%3Fid%3D10.1371%2Fjournal.pbio.1002456)•

23 min

Beginning January 2014, Psychological Science gave authors the opportunity to signal open data and materials if they qualified for badges that accompanied published articles. Before badges, less than 3% of Psychological Science articles reported open data.

[C](https://app.getpocket.com/read/2980984744)

[CoMSES Net](https://app.getpocket.com/read/2980984744)

[comses.net](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.comses.net%2Fresources%2Fopen-code-badge%2F)•

1 min

In order to be awarded an Open Code badge, all source code should be made publicly available in a searchable, open access, trusted digital repository.

[B](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dbadging%2Bfor%2Breproducibility%2Bin%2Buniversity%2Bgraduates%26rlz%3D1C1CHBF_en-GBAU840AU840%26sxsrf%3DALeKk02yOBCZFO53SgvOu6L85J6A0KMf4A%3A1589229850601%26tbm%3Disch%26source%3Diu%26ictx%3D1%26fir%3DZJ-YkoyBbpsfFM%25253A%25252Cs8QBbP2kt5j5lM%25252C_%26vet%3D1%26usg%3DAI4_-kRQE-xDQPLS4Euj9wZKI3FGNPEmwg%26sa%3DX%26ved%3D2ahUKEwjXnNjF1qzpAhU0xjgGHQEJDMYQ9QEwC3oECAoQBw%23imgrc%3DZJ-YkoyBbpsfFM%3A)

[badging for reproducibility in university graduates - Google Search](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dbadging%2Bfor%2Breproducibility%2Bin%2Buniversity%2Bgraduates%26rlz%3D1C1CHBF_en-GBAU840AU840%26sxsrf%3DALeKk02yOBCZFO53SgvOu6L85J6A0KMf4A%3A1589229850601%26tbm%3Disch%26source%3Diu%26ictx%3D1%26fir%3DZJ-YkoyBbpsfFM%25253A%25252Cs8QBbP2kt5j5lM%25252C_%26vet%3D1%26usg%3DAI4_-kRQE-xDQPLS4Euj9wZKI3FGNPEmwg%26sa%3DX%26ved%3D2ahUKEwjXnNjF1qzpAhU0xjgGHQEJDMYQ9QEwC3oECAoQBw%23imgrc%3DZJ-YkoyBbpsfFM%3A)

[Google](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dbadging%2Bfor%2Breproducibility%2Bin%2Buniversity%2Bgraduates%26rlz%3D1C1CHBF_en-GBAU840AU840%26sxsrf%3DALeKk02yOBCZFO53SgvOu6L85J6A0KMf4A%3A1589229850601%26tbm%3Disch%26source%3Diu%26ictx%3D1%26fir%3DZJ-YkoyBbpsfFM%25253A%25252Cs8QBbP2kt5j5lM%25252C_%26vet%3D1%26usg%3DAI4_-kRQE-xDQPLS4Euj9wZKI3FGNPEmwg%26sa%3DX%26ved%3D2ahUKEwjXnNjF1qzpAhU0xjgGHQEJDMYQ9QEwC3oECAoQBw%23imgrc%3DZJ-YkoyBbpsfFM%3A)

[](https://app.getpocket.com/read/2602379977)

[A solution to psychology’s reproducibility problem just failed its first test](https://app.getpocket.com/read/2602379977)

[science](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.sciencemag.org%2Fnews%2F2019%2F05%2Fsolution-psychology-s-reproducibility-problem-just-failed-its-first-test)•

3 min

Behavior change is difficult—just ask any psychologist. A new study shows behavior change among psychologists is no different.

[](https://app.getpocket.com/read/1873879172)

[Bias in Open Science Advocacy: The Case of Article Badges for Data Sharing](https://app.getpocket.com/read/1873879172)

[blogs.plos.org](https://getpocket.com/redirect?url=https%3A%2F%2Fblogs.plos.org%2Fabsolutely-maybe%2F2017%2F08%2F29%2Fbias-in-open-science-advocacy-the-case-of-article-badges-for-data-sharing%2F)•

13 min

I like badges – I have a lot of them! I’m also an open science advocate. So when a group of advocates declared their badges for authors were dramatically increasing open practice, I could have been a lock for the cheer squad. But, no, I’m not.

[F](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.scopus.fr%2F)

[FABRICATION CARTE PLASTIQUE / BADGES, IMPRESSION CARTE DE FIDELITE SCOPUS - OMNIBADGES](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.scopus.fr%2F)

[scopus.fr](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.scopus.fr%2F)

[](https://app.getpocket.com/read/1333957515)

[Result and Artifact Review and Badging](https://app.getpocket.com/read/1333957515)

[acm.org](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.acm.org%2Fpublications%2Fpolicies%2Fartifact-review-badging)•

9 min

An experimental result is not fully established unless it can be independently reproduced.

[](https://app.getpocket.com/read/2739684824)

[How to change the font color?](https://app.getpocket.com/read/2739684824)

[Stack Overflow](https://getpocket.com/redirect?url=https%3A%2F%2Fstackoverflow.com%2Fquestions%2F29067541%2Fhow-to-change-the-font-color)•

3 min

In RMarkdown is there a way to specify the font color? However, it does not work if you select pdf (beamer) as output format. If you want to create a pdf, use LaTeX syntax:

[A](https://app.getpocket.com/read/2973749827)

[Announcing NISO’s Draft Recommended Practice for Reproducibility Badging and Definitions](https://app.getpocket.com/read/2973749827)

[niso.org](https://getpocket.com/redirect?url=http%3A%2F%2Fniso.org%2Fniso-io%2F2020%2F05%2Fannouncing-nisos-draft-recommended-practice-reproducibility-badging-and-definitions)•

2 min

May 5, 2020: The National Information Standards Organization (NISO) is seeking comments from the information community on the draft recommended practice, Reproducibility Badging and Definitions. Following on the landmark U.S.

[](https://app.getpocket.com/read/2962816880)

[Building a Shiny app with an HTML template](https://app.getpocket.com/read/2962816880)

[Stack Overflow](https://getpocket.com/redirect?url=https%3A%2F%2Fstackoverflow.com%2Fquestions%2F60264994%2Fbuilding-a-shiny-app-with-an-html-template)•

4 min

I'm trying to build a Shiny app using an HTML template, as specified in the docs. I'm using Bulma as the CSS framework, and because the app has many graphics I've decided to use tabs to separate them.

[S](https://getpocket.com/redirect?url=https%3A%2F%2Fshields.io%2F)

[Shields.io: Quality metadata badges for open source projects](https://getpocket.com/redirect?url=https%3A%2F%2Fshields.io%2F)

[shields.io](https://getpocket.com/redirect?url=https%3A%2F%2Fshields.io%2F)•

2 min

Love Shields? Please consider donating to sustain our activities Using dash "-" separator https://img.shields.io/badge/&lt;LABEL&gt;-&lt;MESSAGE&gt;-&lt;COLOR&gt; Using query string parameters https://img.shields.io/static/v1?label=&lt;LABEL&gt;&message=&lt;MESSAGE&gt;&color=&lt;COLOR&gt; Colors Endpoint https://img.shields.

[](https://app.getpocket.com/read/2939159000)

[creating name badges/label cards using R](https://app.getpocket.com/read/2939159000)

[community.rstudio.com](https://getpocket.com/redirect?url=https%3A%2F%2Fcommunity.rstudio.com%2Ft%2Fcreating-name-badges-label-cards-using-r%2F22406%2F4)

Is it possible to create name badges/label cards/business card using R? I know one can make business cards using pagedown (https://github.

[R](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Frlz%3D1C1GCEB_enAU867AU867%26sxsrf%3DALeKk03A9ucMyGsJBIlvWt74GN8NzaqWrA%253A1586052147147%26ei%3DMzyJXoPECJDjz7sPqZG8wAU%26q%3DR%2Bpackage%2B%2Bbadges%2Bin%2BRMarkdown%26oq%3DR%2Bpackage%2B%2Bbadges%2Bin%2BRMarkdown%26gs_lcp%3DCgZwc3ktYWIQA0oKCBcSBjEyLTE4N0oICBgSBDEyLTZQ4nJYoH1g0H5oAHAAeAGAAZECiAH2EJIBBTAuNy40mAEAoAEBqgEHZ3dzLXdpeg%26sclient%3Dpsy-ab%26ved%3D0ahUKEwjDqc3WmNDoAhWQ8XMBHakID1gQ4dUDCAw%26uact%3D5)

[R package badges in RMarkdown](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Frlz%3D1C1GCEB_enAU867AU867%26sxsrf%3DALeKk03A9ucMyGsJBIlvWt74GN8NzaqWrA%253A1586052147147%26ei%3DMzyJXoPECJDjz7sPqZG8wAU%26q%3DR%2Bpackage%2B%2Bbadges%2Bin%2BRMarkdown%26oq%3DR%2Bpackage%2B%2Bbadges%2Bin%2BRMarkdown%26gs_lcp%3DCgZwc3ktYWIQA0oKCBcSBjEyLTE4N0oICBgSBDEyLTZQ4nJYoH1g0H5oAHAAeAGAAZECiAH2EJIBBTAuNy40mAEAoAEBqgEHZ3dzLXdpeg%26sclient%3Dpsy-ab%26ved%3D0ahUKEwjDqc3WmNDoAhWQ8XMBHakID1gQ4dUDCAw%26uact%3D5)

[Google](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Frlz%3D1C1GCEB_enAU867AU867%26sxsrf%3DALeKk03A9ucMyGsJBIlvWt74GN8NzaqWrA%253A1586052147147%26ei%3DMzyJXoPECJDjz7sPqZG8wAU%26q%3DR%2Bpackage%2B%2Bbadges%2Bin%2BRMarkdown%26oq%3DR%2Bpackage%2B%2Bbadges%2Bin%2BRMarkdown%26gs_lcp%3DCgZwc3ktYWIQA0oKCBcSBjEyLTE4N0oICBgSBDEyLTZQ4nJYoH1g0H5oAHAAeAGAAZECiAH2EJIBBTAuNy40mAEAoAEBqgEHZ3dzLXdpeg%26sclient%3Dpsy-ab%26ved%3D0ahUKEwjDqc3WmNDoAhWQ8XMBHakID1gQ4dUDCAw%26uact%3D5)

These helpers produce the markdown text you need in your README to include badges that report information, such as the CRAN version or test coverage, and ...

[](https://app.getpocket.com/read/2980367975)

[Open Science Badges](https://app.getpocket.com/read/2980367975)

[cos.io](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.cos.io%2Fbadges)•

1 min

Journal of Experimental Psychology: Learning, Memory, and Cognition | APA Journal of Experimental Social Psychology | Elsevier Journal of International Crisis and Risk Communication Research | Nicholson School of Communication and Media Journal of Maps | Taylor & Francis Journal of Neuroendocrinolog

[B](https://app.getpocket.com/read/2182947692)

[Badges to Acknowledge Open Practices](https://app.getpocket.com/read/2182947692)

[osf.io](https://getpocket.com/redirect?url=https%3A%2F%2Fosf.io%2Ftvyxz%2Fwiki%2F2.%2520Awarding%2520Badges%2F)

This page is currently connected to the collaborative wiki. All edits made will be visible to contributors with write permission in real time. Changes will be stored but not published until you click the "Save" button.

[1](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F322608576_Badges_for_sharing_data_and_code_at_Biostatistics_an_observational_study)

[(19) (PDF) Badges for sharing data and code at Biostatistics: an observatio](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F322608576_Badges_for_sharing_data_and_code_at_Biostatistics_an_observational_study)

[ResearchGate](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F322608576_Badges_for_sharing_data_and_code_at_Biostatistics_an_observational_study)

[](https://app.getpocket.com/read/1888636181)

[Reproducible Research Badges](https://app.getpocket.com/read/1888636181)

[o2r.info](https://getpocket.com/redirect?url=https%3A%2F%2Fo2r.info%2F2017%2F09%2F12%2Freproducible-research-badges%2F)•

14 min

This blog post presents work based on the study project Badges for computational geoscience containers at ifgi. We thank the project team for their valuable contributions! Today badges are widely used in open source software repositories.

[O](https://app.getpocket.com/read/2615946130)

[Open Practice Badges](https://app.getpocket.com/read/2615946130)

[psychologicalscience.org](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.psychologicalscience.org%2Fpublications%2Fbadges)•

3 min

Starting in 2014, authors of accepted manuscripts in Psychological Science, Clinical Psychological Science, and Advances in Methods and Practices in Psychological Science are eligible to earn up to three badges in recognition of open scientific practices.

[M](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dmendeley%2Band%2Bosf%2Bbadges%26rlz%3D1C1CHBF_en-GB%26oq%3Dmendeley%2Band%2Bosf%2Bbadges%26aqs%3Dchrome..69i57.5299j0j7%26sourceid%3Dchrome%26ie%3DUTF-8)

[mendeley and osf badges - Google Search](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dmendeley%2Band%2Bosf%2Bbadges%26rlz%3D1C1CHBF_en-GB%26oq%3Dmendeley%2Band%2Bosf%2Bbadges%26aqs%3Dchrome..69i57.5299j0j7%26sourceid%3Dchrome%26ie%3DUTF-8)

[Google](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dmendeley%2Band%2Bosf%2Bbadges%26rlz%3D1C1CHBF_en-GB%26oq%3Dmendeley%2Band%2Bosf%2Bbadges%26aqs%3Dchrome..69i57.5299j0j7%26sourceid%3Dchrome%26ie%3DUTF-8)•

2 min

Google Open Science Badges - Center for Open Science https://www.cos.io › badges Open Science Badges enhance openness,a core value of scientific practice. ... now: https://osf.io/tvyxz/files/; We offer examples of how to display badges on ...

[B](https://app.getpocket.com/read/2182947705)

[Badges to Acknowledge Open Practices](https://app.getpocket.com/read/2182947705)

[osf.io](https://getpocket.com/redirect?url=https%3A%2F%2Fosf.io%2Ftvyxz%2Fwiki%2F2.%2520Awarding%2520Badges%2F%3F_ga%3D2.260517133.1420078275.1525996125-902006626.1525996125)

This page is currently connected to the collaborative wiki. All edits made will be visible to contributors with write permission in real time. Changes will be stored but not published until you click the "Save" button.

[](https://getpocket.com/redirect?url=https%3A%2F%2Fcos.io%2Four-services%2Fopen-science-badges%2F)

[Open Science Badges](https://getpocket.com/redirect?url=https%3A%2F%2Fcos.io%2Four-services%2Fopen-science-badges%2F)

[cos.io](https://getpocket.com/redirect?url=https%3A%2F%2Fcos.io%2Four-services%2Fopen-science-badges%2F)•

18 min

There is no central authority determining the validity of scientific claims. Accumulation of scientific knowledge proceeds via open communication with the community. Sharing evidence for scientific claims facilitates critique, extension, and application.

[](https://app.getpocket.com/read/2585080083)

[The Royal Baby and Blackness as a Badge of Honor](https://app.getpocket.com/read/2585080083)

[The New York Times](https://getpocket.com/redirect?url=https%3A%2F%2Fwww.nytimes.com%2F2019%2F05%2F07%2Fopinion%2Froyal-baby-race-meghan-markle.html%3Fpartner%3DIFTTT)•

4 min

Whether he “looks” black or not, I’ll be glad to claim him. Ms. Skurnick is a writer.

### Open Science Badges

[News](https://www.cos.io/about/news)

[OSF](https://www.cos.io/osf)

[OSF Collections](https://www.cos.io/collections)

[OSF Institutions](https://www.cos.io/institutions)

[OSF Meetings](https://www.cos.io/our-products/osf-meetings)

[OSF Preprints](https://www.cos.io/preprints)

[OSF Registries](https://www.cos.io/registries)

[SHARE](https://www.cos.io/our-products/osf-share)

[Product Roadmap](https://www.cos.io/our-products/product-roadmap)

- About **osf.io**
    - [Mission](https://www.cos.io/about/mission)
    - [Board](https://www.cos.io/board)
    - [Finances](https://www.cos.io/about/our-finances)
    - [COS Team](https://www.cos.io/team)
    - [Sponsors](https://www.cos.io/about/our-sponsors)
    - [Partners](https://www.cos.io/about/our-partners)
    - [Diversity and Inclusion](https://www.cos.io/diversity-equity-and-inclusion-at-cos)
- Our Products
    - 
- Our Services
    - [Research](https://www.cos.io/our-services/research)
    - [Training Services](https://www.cos.io/training)
    - [Registered Reports](https://www.cos.io/rr)
    - [Preregistration](https://www.cos.io/prereg)
    - [Policy and Norms](https://www.cos.io/policy)
    - [TOP Guidelines](https://www.cos.io/top)
    - [TOP for Funders](https://www.cos.io/top-funders)
    - [Open Science Badges](https://www.cos.io/badges)
    - [Webinars](https://www.cos.io/webinars)
- Our Communities
    - [COS Ambassadors](https://www.cos.io/ambassadors)
    - [Scientists and Researchers](https://www.cos.io/our-communities/scientists-and-researchers)
    - [Research Institutions](https://www.cos.io/our-communities/research-institutions)
    - [Journals and Societies](https://www.cos.io/our-communities/journals-and-societies)
    - [Software Developers](https://www.cos.io/developers)
    - [Open Scholarship Knowledge Base](https://www.cos.io/oskb)
- [Blog](https://www.cos.io/blog)
- [Contact Us](https://www.cos.io/contact)

# Open Science Badges enhance openness,a core value of scientific practice.

<img width="345" height="280" src="../_resources/0de9d045c3094bf0b56ca037525f70ea.png"/>

<img width="345" height="292" src="../_resources/25314eb7f2e64079a869111ab71e9d04.png"/>

#### **What are Open Science Badges?**

- Badges to acknowledge open science practices are incentives for researchers to share data, materials, or to [preregister](http://cos.io/our-services/prereg/)
- Badges signal to the reader that the content has been made available and certify its accessibility in a persistent location.
- Currently, **67 **journals offer Open Science Badges to signal and reward when underlying data, materials, or preregistrations are available, see below. 

* * *

#### **Badges seem silly. Do they work?**

- Yes. Implementing badges is associated with increasing rate of data sharing ([Kidwell et al, 2016](http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002456)), as seeing colleagues practice open science signals that new community norms have arrived.
- For this to occur, badges must be visible on the table of contents and authors must be consistently asked to participate. See the current issue of [Psychological Science](https://journals.sagepub.com/toc/pss/current) for an example of how these new norms look in practice.

* * *

#### **Alright, I'm on board. What are the next steps?**

- Each journal may choose to award badges based on a simple author [disclosure statement or through independent peer review](https://osf.io/tvyxz/wiki/2.%20Awarding%20Badges/).
- The badges are free to use with attribution of their source. Download the images and get started now: [https://osf.io/tvyxz/files/](https://osf.io/tvyxz/files/)
- We offer examples of how to display badges on publications. As long as the badge image and [disclosure statement](https://osf.io/5fndw/) are presented, you can display them any way you like. 

#### Journals That Issue Open Science Badges

[Addiction Research & Theory](https://tandfonline.com/action/authorSubmission?show=instructions&journalCode=iart20) | Taylor & Francis

[Advances in Methods and Practices in Psychological Science](https://journals.sagepub.com/home/amp) | SAGE

[AIS Transactions on Replication Research](https://aisel.aisnet.org/trr/) | Elsevier

[American Journal of Orthopsychiatry](http://www.apa.org/pubs/journals/ort/index.aspx?tab=4) | APA

[American Journal of Political Science](https://ajps.org/) | Wiley

[American Journal of Primatology](https://onlinelibrary.wiley.com/page/journal/10982345/homepage/forauthors.html) | Wiley

[Analyses of Social Issues and Public Policy (ASAP)](https://spssi.onlinelibrary.wiley.com/hub/journal/15302415/about/author-guidelines) | Wiley

[Annual Review of Applied Linguistics](https://www.cambridge.org/core/journals/annual-review-of-applied-linguistics) | Cambridge University Press

[Archive for the Psychology of Religion](https://us.sagepub.com/en-us/nam/archive-for-the-psychology-of-religion/journal203533#submission-guidelines) | SAGE

[Asian American Journal of Psychology](http://www.apa.org/pubs/journals/aap/index.aspx?tab=4) | APA

[BMC Microbiology](https://bmcmicrobiol.biomedcentral.com/open-data-badge) (uses modified badge criteria) | BMC

[BMJ Open Science](https://openscience.bmj.com/pages/authors/) | BMJ

[Brain and Neuroscience Advances](https://journals.sagepub.com/home/bna) | SAGE

[Canadian Journal of Experimental Psychology (CJEP)](http://www.apa.org/pubs/journals/cep/?tab=4) | APA

[Clinical Psychological Science](https://www.psychologicalscience.org/publications/clinical/2016-clinical-submission-guidelines) | APS

[Cognitive Science](https://onlinelibrary.wiley.com/page/journal/15516709/homepage/forauthors.html) | Wiley

[Communication Studies](https://tandfonline.com/action/authorSubmission?journalCode=rcst20&page=instructions#osb) | Taylor & Francis

[Communication Research Reports](https://www.tandfonline.com/loi/rcrr20) | Taylor & Francis

[Cortex](https://www.journals.elsevier.com/cortex/) | Elsevier

[Cultural Diversity & Ethnic Minority Psychology](http://www.apa.org/pubs/journals/cdp/?tab=4) | APA

[Decision](https://www.apa.org/pubs/journals/dec/index?tab=4) | APA

[Ear and Hearing](https://journals.lww.com/ear-hearing/pages/default.aspx) | Wolters Kluwer

[Emerging Adulthood](https://us.sagepub.com/en-us/nam/journal/emerging-adulthood#submission-guidelines) | SAGE

[Environmental Toxicology and Chemistry](https://wol-prod-cdn.literatumonline.com/pb-assets/assets/15528618/updated_ETC%20Manuscript%20Preparation_December%202018-1547757527743.pdf)  | Wiley

[European Journal of Personality](https://onlinelibrary.wiley.com/journal/10990984) | Wiley

[Evolution and Human Behavior](https://www.ehbonline.org/content/authorinfo#idp1491248) | Elsevier

[Exceptional Children](https://us.sagepub.com/en-us/nam/journal/exceptional-children#submission-guidelines) | SAGE

[Geoscience Data Journal](https://rmets.onlinelibrary.wiley.com/hub/journal/20496060/about/author-guidelines) | Wiley

[Gifted Child Quarterly](https://journals.sagepub.com/home/gcq) | SAGE

[International Gambling Studies](https://tandfonline.com/toc/rigs20/current) | Taylor & Francis

[International Journal for the Psychology of Religion](https://www.tandfonline.com/toc/hjpr20/current) |  Taylor & Francis

[International Journal of Primatology](https://www.springer.com/life+sciences/evolutionary+&+developmental+biology/journal/10764) | Springer Nature

[Internet Archaeology](http://intarch.ac.uk/about/open-badges/) | University of York

[Journal of Behavioral Public Administration](https://journal-bpa.org/index.php/jbpa/transparency) (JBPA)

[Journal of Cognition and Development](https://www.tandfonline.com/action/authorSubmission?journalCode=hjcd20&page=instructions) | Taylor & Francis

[Journal of Comparative Psychology](https://www.apa.org/pubs/journals/com/index?tab=4) | APA

[Journal of Experimental Psychology: Learning, Memory, and Cognition](https://www.apa.org/pubs/journals/xlm?tab=4) | APA

[Journal of Experimental Social Psychology](https://www.sciencedirect.com/journal/journal-of-experimental-social-psychology) | Elsevier

[Journal of International Crisis and Risk Communication Research](https://stars.library.ucf.edu/jicrcr/osb.html) | [Nicholson School of Communication and Media](https://communication.ucf.edu/)

[Journal of Maps](https://www.tandfonline.com/toc/tjom20/current) | Taylor & Francis

[Journal of Neuroendocrinology](https://onlinelibrary.wiley.com/page/journal/13652826/homepage/forauthors.html) | Wiley

[Journal of Neurochemistry](https://onlinelibrary.wiley.com/page/journal/14714159/homepage/forauthors.html#Open%20Practice%20Badges) | Wiley

[Journal of Neuroscience Research (JNR)](https://onlinelibrary.wiley.com/page/journal/10974547/homepage/forauthors.html) | Wiley

[Journal of Personality Assessment](https://www.tandfonline.com/action/authorSubmission?journalCode=hjpa20&page=instructions) | Taylor & Francis

[Journal of Psychiatric and Mental Health Nursing](https://onlinelibrary.wiley.com/page/journal/13652850/homepage/forauthors.html) | Wiley

[Journal of Social Psychology](https://www.tandfonline.com/toc/vsoc20/current#.VMK4RmTF9o9) | Taylor & Francis

[Journal of Research in Personality](https://www.journals.elsevier.com/journal-of-research-in-personality/) | Elsevier

[Journal of Research on Educational Effectiveness](https://tandfonline.com/toc/uree20/current) | Taylor & Francis

[Journal of Threat Assessment and Management](https://www.apa.org/pubs/journals/tam?tab=4) | APA

[Language Learning](https://onlinelibrary.wiley.com/page/journal/14679922/homepage/ForAuthors.html) | Wiley

[Language Testing](https://journals.sagepub.com/home/ltj) | SAGE

[Law and Human Behavior](http://www.apa.org/pubs/journals/lhb/index.aspx?tab=4) | APA

[Management and Organization Review](https://www.cambridge.org/core/journals/management-and-organization-review) | Cambridge University Press

[Meta-Psychology](https://open.lnu.se/index.php/metapsychology/about) | Linnaeus University Press

[Neuropsychology](http://www.apa.org/pubs/journals/neu/index.aspx?tab=4) | APA

[Neuroscience of Consciousness](https://academic.oup.com/nc) | Oxford University Press

[Political Communication](https://www.tandfonline.com/action/authorSubmission?journalCode=upcp20&page=instructions#osb) | Taylor & Francis

[Psi Chi Journal of Psychological Research](https://www.psichi.org/page/journal_main#.W47h65NKhBx) | Psi Chi

[Psychological Science](https://www.psychologicalscience.org/publications/psychological_science) | SAGE

[Psychological Methods](http://www.apa.org/pubs/journals/met/?tab=4) | APA

[Psychology of Addictive Behaviors](https://www.apa.org/pubs/journals/adb/) | APA

[Psychology of Men & Masculinity](http://www.apa.org/pubs/journals/men/index.aspx?tab=4) | APA

[Psychology of Popular Media Culture](http://www.apa.org/pubs/journals/ppm/index.aspx?tab=4) | APA

[Public Administration Review](https://www.publicadministrationreview.com/guidelines/) | [ASPA](https://www.aspanet.org/)

[Quarterly Journal of Experimental Psychology](https://us.sagepub.com/en-us/nam/quarterly-journal-of-experimental-psychology/journal203389#submission-guidelines) | SAGE

[Sexual Abuse](https://us.sagepub.com/en-us/nam/sexual-abuse/journal201888#submission-guidelines) | SAGE

[Social Psychology](https://us.hogrefe.com/products/journals/social-psychology) | Hogrefe

[Strategic Management Journal](https://onlinelibrary.wiley.com/page/journal/10970266/homepage/forauthors.html) | Wiley

[Studies in Second Language Acquisition](https://www.cambridge.org/core/journals/studies-in-second-language-acquisition) | Cambridge University Press

[The Modern Language Journal](https://onlinelibrary.wiley.com/page/journal/15404781/homepage/forauthors.html) | Wiley

[The Photogrammetric Record](https://onlinelibrary.wiley.com/page/journal/14779730/homepage/forauthors.html) | Wiley

[Addiction Research & Theory](https://tandfonline.com/action/authorSubmission?show=instructions&journalCode=iart20) | Taylor & Francis

[Advances in Methods and Practices in Psychological Science](https://journals.sagepub.com/home/amp) | SAGE

[AIS Transactions on Replication Research](https://aisel.aisnet.org/trr/) | Elsevier

[American Journal of Orthopsychiatry](http://www.apa.org/pubs/journals/ort/index.aspx?tab=4) | APA

[American Journal of Political Science](https://ajps.org/) | Wiley

[American Journal of Primatology](https://onlinelibrary.wiley.com/page/journal/10982345/homepage/forauthors.html) | Wiley

[Analyses of Social Issues and Public Policy (ASAP)](https://spssi.onlinelibrary.wiley.com/hub/journal/15302415/about/author-guidelines) | Wiley

[Annual Review of Applied Linguistics](https://www.cambridge.org/core/journals/annual-review-of-applied-linguistics) | Cambridge University Press

[Archive for the Psychology of Religion](https://us.sagepub.com/en-us/nam/archive-for-the-psychology-of-religion/journal203533#submission-guidelines) | SAGE

[Asian American Journal of Psychology](http://www.apa.org/pubs/journals/aap/index.aspx?tab=4) | APA

[BMC Microbiology](https://bmcmicrobiol.biomedcentral.com/open-data-badge) (uses modified badge criteria) | BMC

[BMJ Open Science](https://openscience.bmj.com/pages/authors/) | BMJ

[Brain and Neuroscience Advances](https://journals.sagepub.com/home/bna) | SAGE

[Canadian Journal of Experimental Psychology (CJEP)](http://www.apa.org/pubs/journals/cep/?tab=4) | APA

[Clinical Psychological Science](https://www.psychologicalscience.org/publications/clinical/2016-clinical-submission-guidelines) | APS

[Cognitive Science](https://onlinelibrary.wiley.com/page/journal/15516709/homepage/forauthors.html) | Wiley

[Communication Studies](https://tandfonline.com/action/authorSubmission?journalCode=rcst20&page=instructions#osb) | Taylor & Francis

[Communication Research Reports](https://www.tandfonline.com/loi/rcrr20) | Taylor & Francis

[Cortex](https://www.journals.elsevier.com/cortex/) | Elsevier

[Cultural Diversity & Ethnic Minority Psychology](http://www.apa.org/pubs/journals/cdp/?tab=4) | APA

[Decision](https://www.apa.org/pubs/journals/dec/index?tab=4) | APA

[Ear and Hearing](https://journals.lww.com/ear-hearing/pages/default.aspx) | Wolters Kluwer

[Emerging Adulthood](https://us.sagepub.com/en-us/nam/journal/emerging-adulthood#submission-guidelines) | SAGE

[Environmental Toxicology and Chemistry](https://wol-prod-cdn.literatumonline.com/pb-assets/assets/15528618/updated_ETC%20Manuscript%20Preparation_December%202018-1547757527743.pdf)  | Wiley

[European Journal of Personality](https://onlinelibrary.wiley.com/journal/10990984) | Wiley

[Evolution and Human Behavior](https://www.ehbonline.org/content/authorinfo#idp1491248) | Elsevier

[Exceptional Children](https://us.sagepub.com/en-us/nam/journal/exceptional-children#submission-guidelines) | SAGE

[Geoscience Data Journal](https://rmets.onlinelibrary.wiley.com/hub/journal/20496060/about/author-guidelines) | Wiley

[Gifted Child Quarterly](https://journals.sagepub.com/home/gcq) | SAGE

[International Gambling Studies](https://tandfonline.com/toc/rigs20/current) | Taylor & Francis

[International Journal for the Psychology of Religion](https://www.tandfonline.com/toc/hjpr20/current) |  Taylor & Francis

[International Journal of Primatology](https://www.springer.com/life+sciences/evolutionary+&+developmental+biology/journal/10764) | Springer Nature

[Internet Archaeology](http://intarch.ac.uk/about/open-badges/) | University of York

[Journal of Behavioral Public Administration](https://journal-bpa.org/index.php/jbpa/transparency) (JBPA)

[Journal of Cognition and Development](https://www.tandfonline.com/action/authorSubmission?journalCode=hjcd20&page=instructions) | Taylor & Francis

[Journal of Comparative Psychology](https://www.apa.org/pubs/journals/com/index?tab=4) | APA

[Journal of Experimental Psychology: Learning, Memory, and Cognition](https://www.apa.org/pubs/journals/xlm?tab=4) | APA

[Journal of Experimental Social Psychology](https://www.sciencedirect.com/journal/journal-of-experimental-social-psychology) | Elsevier

[Journal of International Crisis and Risk Communication Research](https://stars.library.ucf.edu/jicrcr/osb.html) | [Nicholson School of Communication and Media](https://communication.ucf.edu/)

[Journal of Maps](https://www.tandfonline.com/toc/tjom20/current) | Taylor & Francis

[Journal of Neuroendocrinology](https://onlinelibrary.wiley.com/page/journal/13652826/homepage/forauthors.html) | Wiley

[Journal of Neurochemistry](https://onlinelibrary.wiley.com/page/journal/14714159/homepage/forauthors.html#Open%20Practice%20Badges) | Wiley

[Journal of Neuroscience Research (JNR)](https://onlinelibrary.wiley.com/page/journal/10974547/homepage/forauthors.html) | Wiley

[Journal of Personality Assessment](https://www.tandfonline.com/action/authorSubmission?journalCode=hjpa20&page=instructions) | Taylor & Francis

[Journal of Psychiatric and Mental Health Nursing](https://onlinelibrary.wiley.com/page/journal/13652850/homepage/forauthors.html) | Wiley

[Journal of Social Psychology](https://www.tandfonline.com/toc/vsoc20/current#.VMK4RmTF9o9) | Taylor & Francis

[Journal of Research in Personality](https://www.journals.elsevier.com/journal-of-research-in-personality/) | Elsevier

[Journal of Research on Educational Effectiveness](https://tandfonline.com/toc/uree20/current) | Taylor & Francis

[Journal of Threat Assessment and Management](https://www.apa.org/pubs/journals/tam?tab=4) | APA

[Language Learning](https://onlinelibrary.wiley.com/page/journal/14679922/homepage/ForAuthors.html) | Wiley

[Language Testing](https://journals.sagepub.com/home/ltj) | SAGE

[Law and Human Behavior](http://www.apa.org/pubs/journals/lhb/index.aspx?tab=4) | APA

[Management and Organization Review](https://www.cambridge.org/core/journals/management-and-organization-review) | Cambridge University Press

[Meta-Psychology](https://open.lnu.se/index.php/metapsychology/about) | Linnaeus University Press

[Neuropsychology](http://www.apa.org/pubs/journals/neu/index.aspx?tab=4) | APA

[Neuroscience of Consciousness](https://academic.oup.com/nc) | Oxford University Press

[Political Communication](https://www.tandfonline.com/action/authorSubmission?journalCode=upcp20&page=instructions#osb) | Taylor & Francis

[Psi Chi Journal of Psychological Research](https://www.psichi.org/page/journal_main#.W47h65NKhBx) | Psi Chi

[Psychological Science](https://www.psychologicalscience.org/publications/psychological_science) | SAGE

[Psychological Methods](http://www.apa.org/pubs/journals/met/?tab=4) | APA

[Psychology of Addictive Behaviors](https://www.apa.org/pubs/journals/adb/) | APA

[Psychology of Men & Masculinity](http://www.apa.org/pubs/journals/men/index.aspx?tab=4) | APA

[Psychology of Popular Media Culture](http://www.apa.org/pubs/journals/ppm/index.aspx?tab=4) | APA

[Public Administration Review](https://www.publicadministrationreview.com/guidelines/) | [ASPA](https://www.aspanet.org/)

[Quarterly Journal of Experimental Psychology](https://us.sagepub.com/en-us/nam/quarterly-journal-of-experimental-psychology/journal203389#submission-guidelines) | SAGE

[Sexual Abuse](https://us.sagepub.com/en-us/nam/sexual-abuse/journal201888#submission-guidelines) | SAGE

[Social Psychology](https://us.hogrefe.com/products/journals/social-psychology) | Hogrefe

[Strategic Management Journal](https://onlinelibrary.wiley.com/page/journal/10970266/homepage/forauthors.html) | Wiley

[Studies in Second Language Acquisition](https://www.cambridge.org/core/journals/studies-in-second-language-acquisition) | Cambridge University Press

[The Modern Language Journal](https://onlinelibrary.wiley.com/page/journal/15404781/homepage/forauthors.html) | Wiley

[The Photogrammetric Record](https://onlinelibrary.wiley.com/page/journal/14779730/homepage/forauthors.html) | Wiley



## Approach

Asked 4 years, 6 months ago

Viewed 2k times

I have been reading about R Markdown ([here](http://eriqande.github.io/rep-res-web/lectures/learning-rmarkdown-in-an-hour.html), [here](http://rmarkdown.rstudio.com/authoring_basics.html), and [here](http://yihui.name/knitr/demo/externalization/)) and using it to create solid reports. I would like to try to use what little code I am running to do some ad hoc analyses and turn them into more scalable data reports.

My question is rather broad: Is there a proper way to organize your code around an R Markdown project? Say, have one script that generates all of the data structures?

For example: Let's say that I have the `cars` data set and I have brought in commercial data on the manufacturer. What if I wanted to attach the manufacturer to the current `cars` data set, and then produce a separate summary table for each company using a manipulated data set `cars.by.name` as well as plot a certain sample using `cars.import`?

**EDIT:** Right now I have two files open. One is an R Script file that has all of the data manipulation: subsetting and re-categorizing values. And the other is the R Markdown file where I am building out text to accompany the various tables and plots of interest. When I call an object from the R Script file--like:

```
​```{r}
table(cars.by.name$make)
```
```

I get an error saying `Error in summary(cars.by.name$make) : object 'cars.by.name' not found`

**EDIT 2:** I found this older thread to be helpful. [Link](https://stackoverflow.com/questions/10966109/how-to-source-r-markdown-file-like-sourcemyfile-r)

```
---
title: "Untitled"
author: "Jeb"
date: "August 4, 2015"
output: html_document
---


This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
table(cars.by.name$make)
```

```{r}
summary(cars)
summary(cars.by.name)
```

```{r}
table(cars.by.name)
```
You can also embed plots, for example:

```{r, echo=FALSE}
plot(cars)
plot(cars.import)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
```

[![](https://i.stack.imgur.com/z9t89.jpg?s=32&g=1)](https://stackoverflow.com/users/8366499/divibisan)

[divibisan](https://stackoverflow.com/users/8366499/divibisan)

7,11999 gold badges2323 silver badges3737 bronze badges

asked Aug 5 '15 at 3:20

[![](https://www.gravatar.com/avatar/32331ff9cbdb31eb9303025b0ed54ab1?s=32&d=identicon&r=PG)](https://stackoverflow.com/users/5530234/jebediah15)

Often times, I have many reports that need to run the _same_ code with slightly different parameters. Calling all my "stats" functions separately, generating the results and then just referencing is what I typically do. The way to do this is as follows:

```
---
title: "Untitled"
author: "Author"
date: "August 4, 2015"
output: html_document
---

```{r, echo=FALSE, message=FALSE}
directoryPath <- "rawPath" ##Something like /Users/userid/RDataFile
fullPath <- file.path(directoryPath,"myROutputFile.RData") 
load(fullPath)
```

Some Text, headers whatever

```{r}
summary(myStructure$value1) #Where myStructure was saved to the .RData file
```
```

You can save an RData file by using the `save.image()` command.

Hope that helps!

answered Aug 5 '15 at 3:56

[![](https://www.gravatar.com/avatar/14061f142e73d3b085cb4ef6b7fbd567?s=32&d=identicon&r=PG)](https://stackoverflow.com/users/1357015/user1357015)

[user1357015](https://stackoverflow.com/users/1357015/user1357015)user1357015

7,8731313 gold badges4343 silver badges8585 bronze badges

There is a solution for this sort of problem, explained [here](http://yihui.name/knitr/demo/externalization/).

Basically, if you have an .R file containing your code, there is no need to repeat the code in the .Rmd file, but you can include the code from .R file. For this to work, the chunks of code should be named in the .R file, and then can be included by name in the .Rmd file.

## test.R:

```
## ---- chunk-1 ----
table(cars.by.name$make)
```

## test.Rmd

Just once on top of the .Rmd file:

```
```{r echo=FALSE, cache= F}
knitr::read_chunk('test.R')
```
```

For every chunk you're including (replace `chunk-1` with the label of that specific chunk in your .R file):

```
```{r chunk-1}

```
```

Note that it should be left empty (as is) and in run-time your code from .R will be brought over here and run.

answered May 19 '16 at 22:29

[![](https://www.gravatar.com/avatar/d0a76262853171308851632ab78efd4f?s=32&d=identicon&r=PG&f=1)](https://stackoverflow.com/users/2864184/pbahr)

[pbahr](https://stackoverflow.com/users/2864184/pbahr)pbahr

81088 silver badges1313 bronze badges

## Not the answer you're looking for? Browse other questions tagged [r](https://stackoverflow.com/questions/tagged/r "show questions tagged 'r'") [r-markdown](https://stackoverflow.com/questions/tagged/r-markdown "show questions tagged 'r-markdown'") or [ask your own question](https://stackoverflow.com/questions/ask).
```